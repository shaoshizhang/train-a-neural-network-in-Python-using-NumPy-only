{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MMAI5500 Assignment #1",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-M9CblcvlaF"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "fname = 'assign1_data.csv'\n",
        "data = np.loadtxt(fname, dtype='float', delimiter=',', skiprows=1)\n",
        "X, y = data[:, :-1], data[:, -1].astype(int)\n",
        "X_train, y_train = X[:400], y[:400]\n",
        "X_test, y_test = X[400:], y[400:]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Uct6B_xKog"
      },
      "source": [
        "class DenseLayer:\n",
        "\n",
        "    def __init__(self, n_inputs, n_neurons, seed):\n",
        "        np.random.seed(seed)\n",
        "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        self.z = np.dot(self.inputs, self.weights) + self.biases\n",
        "\n",
        "    def backward(self, dz):\n",
        "        self.dweights = np.dot(self.inputs.T, dz)\n",
        "        self.dbiases = np.sum(dz, axis=0, keepdims=True)\n",
        "        self.dinputs = np.dot(dz, self.weights.T)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOK3J0uW0uXn"
      },
      "source": [
        "class ReLu:\n",
        "\n",
        "    def forward(self, z):\n",
        "        self.z = z\n",
        "        self.activity = np.maximum(0, self.z)\n",
        "\n",
        "    def backward(self, dactivity):\n",
        "        self.dz = dactivity.copy()\n",
        "        self.dz[self.z <= 0] = 0.0"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftfOphlZ1mtG"
      },
      "source": [
        "class Softmax:\n",
        "\n",
        "    def forward(self, z):\n",
        "        e_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "        self.probs = e_z / e_z.sum(axis=1, keepdims=True)\n",
        "        return self.probs\n",
        "\n",
        "    def backward(self, dprobs):\n",
        "        self.dz = np.empty_like(dprobs)\n",
        "        for i, (prob, dprob) in enumerate(zip(self.probs, dprobs)):\n",
        "            prob = prob.reshape(-1, 1)\n",
        "            jacobian = np.diagflat(prob) - np.dot(prob, prob.T)\n",
        "            self.dz[i] = np.dot(jacobian, dprob)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXhpy_RA2HT4"
      },
      "source": [
        "class CrossEntropyLoss:\n",
        "\n",
        "    def forward(self, probs, oh_y_true):\n",
        "        probs_clipped = np.clip(probs, 1e-7, 1 - 1e-7)\n",
        "        loss = -np.sum(oh_y_true * np.log(probs_clipped), axis=1)\n",
        "        return loss.mean(axis=0)\n",
        "\n",
        "    def backward(self, probs, oh_y_true):\n",
        "        batch_sz, n_class = probs.shape\n",
        "        self.dprobs = -oh_y_true / probs\n",
        "        self.dprobs = self.dprobs / batch_sz"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RWcsTFE2l7w"
      },
      "source": [
        "class SGD:\n",
        "\n",
        "    def __init__(self, learning_rate=1.0):\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def update_params(self, layer):\n",
        "        layer.weights = layer.weights - self.learning_rate * layer.dweights\n",
        "        layer.biases = layer.biases - self.learning_rate * layer.dbiases"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LlD0gSp5XXn"
      },
      "source": [
        "def predictions(probs):\n",
        "    y_preds = np.argmax(probs, axis=1)\n",
        "    return y_preds"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkmjkeUN5bW9"
      },
      "source": [
        "def accuracy(y_preds, y_true):\n",
        "    return np.mean(y_preds == y_true)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJDZPJqE5j3L"
      },
      "source": [
        "# A single forward pass through the entire network.\n",
        "def forward_pass(X, y_true, oh_y_true):\n",
        "    dense1.forward(X)\n",
        "    activation1.forward(dense1.z)\n",
        "    dense2.forward(activation1.activity)\n",
        "    activation2.forward(dense2.z)\n",
        "    dense3.forward(activation2.activity)\n",
        "    probs = output_activation.forward(dense3.z)\n",
        "    loss = crossentropy.forward(probs, oh_y_true)\n",
        "    return probs, loss"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTHATQCX50OX"
      },
      "source": [
        "# A single backward pass through the entire network.\n",
        "def backward_pass(probs, y_true, oh_y_true):\n",
        "    crossentropy.backward(probs, oh_y_true)\n",
        "    output_activation.backward(crossentropy.dprobs)\n",
        "    dense3.backward(output_activation.dz)\n",
        "    activation2.backward(dense3.dinputs)\n",
        "    dense2.backward(activation2.dz)\n",
        "    activation1.backward(dense2.dinputs)\n",
        "    dense1.backward(activation1.dz)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhYwmc367Lc_"
      },
      "source": [
        "# Initialize the network and set hyperparameters\n",
        "epochs = 10\n",
        "n_class = 3\n",
        "n_batch = 20\n",
        "dense1 = DenseLayer(3, 4, 1)\n",
        "dense2 = DenseLayer(4, 8, 2)\n",
        "dense3 = DenseLayer(8, 3, 3)\n",
        "activation1 = ReLu()\n",
        "activation2 = ReLu()\n",
        "output_activation = Softmax()\n",
        "crossentropy = CrossEntropyLoss()\n",
        "optimizer = SGD()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csoQFcYc7d-7",
        "outputId": "1feeaca6-a066-46a2-f58b-ea5135735a8e"
      },
      "source": [
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    print('epoch:', epoch)\n",
        "    for batch_i in range(n_batch):\n",
        "        x = np.split(X_train, n_batch)[batch_i]\n",
        "        y_true = np.split(y_train, n_batch)[batch_i]\n",
        "        oh_y_true = np.eye(n_class)[y_true]\n",
        "        forward_pass(x, y_true, oh_y_true)\n",
        "        probs, loss = forward_pass(x, y_true, oh_y_true)\n",
        "        y_preds = predictions(probs)\n",
        "        print('Accuracy: ', accuracy(y_preds, y_true), 'Loss: ', loss)\n",
        "        backward_pass(probs, y_true, oh_y_true)\n",
        "        optimizer.update_params(dense3)\n",
        "        optimizer.update_params(dense2)\n",
        "        optimizer.update_params(dense1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "Accuracy:  0.3 Loss:  1.0986093183882306\n",
            "Accuracy:  0.3 Loss:  1.103065175859254\n",
            "Accuracy:  0.4 Loss:  1.0916882286067806\n",
            "Accuracy:  0.35 Loss:  1.0965938478155728\n",
            "Accuracy:  0.25 Loss:  1.100965864399321\n",
            "Accuracy:  0.2 Loss:  1.111827326912512\n",
            "Accuracy:  0.5 Loss:  1.06129740627571\n",
            "Accuracy:  0.25 Loss:  1.1740542352924332\n",
            "Accuracy:  0.3 Loss:  1.1145310704972966\n",
            "Accuracy:  0.1 Loss:  1.1041176663006924\n",
            "Accuracy:  0.25 Loss:  1.1729584787466316\n",
            "Accuracy:  0.5 Loss:  1.1103139591683093\n",
            "Accuracy:  0.2 Loss:  1.1603536287880685\n",
            "Accuracy:  0.4 Loss:  1.0797167402611336\n",
            "Accuracy:  0.15 Loss:  1.180627199662128\n",
            "Accuracy:  0.35 Loss:  1.114466236515785\n",
            "Accuracy:  0.6 Loss:  1.092478013491839\n",
            "Accuracy:  0.25 Loss:  1.1740225413636778\n",
            "Accuracy:  0.25 Loss:  1.0867239302269396\n",
            "Accuracy:  0.35 Loss:  1.117433097325489\n",
            "epoch: 1\n",
            "Accuracy:  0.3 Loss:  1.1219871983402954\n",
            "Accuracy:  0.3 Loss:  1.1054150731735284\n",
            "Accuracy:  0.4 Loss:  1.0997270012013936\n",
            "Accuracy:  0.35 Loss:  1.097315735710261\n",
            "Accuracy:  0.25 Loss:  1.1036754195152993\n",
            "Accuracy:  0.2 Loss:  1.1132351969297047\n",
            "Accuracy:  0.5 Loss:  1.0592925176192498\n",
            "Accuracy:  0.25 Loss:  1.174743847700758\n",
            "Accuracy:  0.3 Loss:  1.113881310353132\n",
            "Accuracy:  0.1 Loss:  1.1050517151757018\n",
            "Accuracy:  0.25 Loss:  1.17300146160178\n",
            "Accuracy:  0.5 Loss:  1.110200469834482\n",
            "Accuracy:  0.2 Loss:  1.1596560463536012\n",
            "Accuracy:  0.4 Loss:  1.079667838858565\n",
            "Accuracy:  0.15 Loss:  1.1808417189531495\n",
            "Accuracy:  0.35 Loss:  1.1142895909235104\n",
            "Accuracy:  0.6 Loss:  1.092564516975364\n",
            "Accuracy:  0.25 Loss:  1.1739452609328074\n",
            "Accuracy:  0.25 Loss:  1.0866441744486197\n",
            "Accuracy:  0.35 Loss:  1.1174424850107336\n",
            "epoch: 2\n",
            "Accuracy:  0.3 Loss:  1.1219552637148191\n",
            "Accuracy:  0.3 Loss:  1.1053952080217777\n",
            "Accuracy:  0.4 Loss:  1.099683669903768\n",
            "Accuracy:  0.35 Loss:  1.0972751954446391\n",
            "Accuracy:  0.25 Loss:  1.1036189401879641\n",
            "Accuracy:  0.2 Loss:  1.113241198735668\n",
            "Accuracy:  0.5 Loss:  1.0592181118626847\n",
            "Accuracy:  0.25 Loss:  1.1747527559583928\n",
            "Accuracy:  0.3 Loss:  1.113818554932402\n",
            "Accuracy:  0.1 Loss:  1.1049265913129245\n",
            "Accuracy:  0.25 Loss:  1.1730865848860852\n",
            "Accuracy:  0.5 Loss:  1.1101148065076418\n",
            "Accuracy:  0.2 Loss:  1.1595661419241357\n",
            "Accuracy:  0.4 Loss:  1.0795692377007873\n",
            "Accuracy:  0.15 Loss:  1.1807075134990508\n",
            "Accuracy:  0.35 Loss:  1.114143796834192\n",
            "Accuracy:  0.6 Loss:  1.0923980935276547\n",
            "Accuracy:  0.25 Loss:  1.1738661336636675\n",
            "Accuracy:  0.25 Loss:  1.0864911006503508\n",
            "Accuracy:  0.35 Loss:  1.117292038643656\n",
            "epoch: 3\n",
            "Accuracy:  0.3 Loss:  1.1215948639591988\n",
            "Accuracy:  0.3 Loss:  1.10515910828099\n",
            "Accuracy:  0.4 Loss:  1.0992277571450646\n",
            "Accuracy:  0.35 Loss:  1.096899261814654\n",
            "Accuracy:  0.25 Loss:  1.1031378469898863\n",
            "Accuracy:  0.2 Loss:  1.1128597890171608\n",
            "Accuracy:  0.5 Loss:  1.0583384323551923\n",
            "Accuracy:  0.25 Loss:  1.1744034777955168\n",
            "Accuracy:  0.3 Loss:  1.1127842725733514\n",
            "Accuracy:  0.1 Loss:  1.102938219359516\n",
            "Accuracy:  0.25 Loss:  1.1724615595285324\n",
            "Accuracy:  0.55 Loss:  1.1086718628059269\n",
            "Accuracy:  0.2 Loss:  1.157529836880991\n",
            "Accuracy:  0.4 Loss:  1.0758208762143395\n",
            "Accuracy:  0.15 Loss:  1.17578196891523\n",
            "Accuracy:  0.35 Loss:  1.107217502942214\n",
            "Accuracy:  0.6 Loss:  1.0815703676314283\n",
            "Accuracy:  0.25 Loss:  1.1652341814937413\n",
            "Accuracy:  0.25 Loss:  1.0709775323514008\n",
            "Accuracy:  0.35 Loss:  1.0905598074695348\n",
            "epoch: 4\n",
            "Accuracy:  0.3 Loss:  1.0665801839462299\n",
            "Accuracy:  0.55 Loss:  1.0263309346386549\n",
            "Accuracy:  0.75 Loss:  0.9285129305600627\n",
            "Accuracy:  0.65 Loss:  0.8507145359711185\n",
            "Accuracy:  0.7 Loss:  0.7049383774198723\n",
            "Accuracy:  0.35 Loss:  0.6554494804208212\n",
            "Accuracy:  0.7 Loss:  0.8231163407505037\n",
            "Accuracy:  0.8 Loss:  0.6083500802869779\n",
            "Accuracy:  0.75 Loss:  0.6011039298978801\n",
            "Accuracy:  0.75 Loss:  0.4389336808940804\n",
            "Accuracy:  0.45 Loss:  0.6258321467985309\n",
            "Accuracy:  0.65 Loss:  0.7337173056136583\n",
            "Accuracy:  0.7 Loss:  0.6654614132295513\n",
            "Accuracy:  0.9 Loss:  0.3685842623440864\n",
            "Accuracy:  0.9 Loss:  0.42839579776932596\n",
            "Accuracy:  0.55 Loss:  0.6526949189698932\n",
            "Accuracy:  0.8 Loss:  0.3990428021356941\n",
            "Accuracy:  0.5 Loss:  0.570531815517335\n",
            "Accuracy:  0.9 Loss:  0.5289315812421859\n",
            "Accuracy:  0.9 Loss:  0.4339301907914912\n",
            "epoch: 5\n",
            "Accuracy:  0.95 Loss:  0.2439713650915\n",
            "Accuracy:  0.8 Loss:  0.4923474806351312\n",
            "Accuracy:  0.9 Loss:  0.24287966711986683\n",
            "Accuracy:  0.9 Loss:  0.27398510651779046\n",
            "Accuracy:  0.9 Loss:  0.20440970654284363\n",
            "Accuracy:  0.95 Loss:  0.2236292759678598\n",
            "Accuracy:  0.85 Loss:  0.47667647706389893\n",
            "Accuracy:  1.0 Loss:  0.11782507411214646\n",
            "Accuracy:  0.9 Loss:  0.24941128093839007\n",
            "Accuracy:  0.95 Loss:  0.1462719599793894\n",
            "Accuracy:  0.75 Loss:  0.3562047275980048\n",
            "Accuracy:  0.75 Loss:  0.6433419311464253\n",
            "Accuracy:  0.8 Loss:  0.37203741605259316\n",
            "Accuracy:  1.0 Loss:  0.10080238927336646\n",
            "Accuracy:  0.85 Loss:  0.36662031117921345\n",
            "Accuracy:  0.95 Loss:  0.24354094109782332\n",
            "Accuracy:  1.0 Loss:  0.08040363443499324\n",
            "Accuracy:  1.0 Loss:  0.24059391262293942\n",
            "Accuracy:  0.9 Loss:  0.3681077555560915\n",
            "Accuracy:  0.9 Loss:  0.35457469159524146\n",
            "epoch: 6\n",
            "Accuracy:  0.9 Loss:  0.22070891687105026\n",
            "Accuracy:  0.8 Loss:  0.5030369280269801\n",
            "Accuracy:  0.85 Loss:  0.27883788307287694\n",
            "Accuracy:  0.9 Loss:  0.2581143161393431\n",
            "Accuracy:  1.0 Loss:  0.12360069092286505\n",
            "Accuracy:  0.85 Loss:  0.2343441967824756\n",
            "Accuracy:  0.85 Loss:  0.684483765364287\n",
            "Accuracy:  1.0 Loss:  0.0696427089910984\n",
            "Accuracy:  0.9 Loss:  0.28681189582274735\n",
            "Accuracy:  0.95 Loss:  0.11012120118426046\n",
            "Accuracy:  0.8 Loss:  0.3739698821642442\n",
            "Accuracy:  0.75 Loss:  0.6795164327932991\n",
            "Accuracy:  0.8 Loss:  0.3482451586025717\n",
            "Accuracy:  1.0 Loss:  0.06866185480648274\n",
            "Accuracy:  0.9 Loss:  0.36904521493448733\n",
            "Accuracy:  0.95 Loss:  0.19004976934333556\n",
            "Accuracy:  1.0 Loss:  0.05529696169708942\n",
            "Accuracy:  1.0 Loss:  0.19628119154221674\n",
            "Accuracy:  0.9 Loss:  0.4516984358905306\n",
            "Accuracy:  0.9 Loss:  0.34354800630765586\n",
            "epoch: 7\n",
            "Accuracy:  0.9 Loss:  0.2335917682466869\n",
            "Accuracy:  0.85 Loss:  0.45422499730920035\n",
            "Accuracy:  0.9 Loss:  0.2058999929008543\n",
            "Accuracy:  0.9 Loss:  0.2757717869639327\n",
            "Accuracy:  1.0 Loss:  0.10645628875826382\n",
            "Accuracy:  0.85 Loss:  0.21266432323296294\n",
            "Accuracy:  0.85 Loss:  0.5763041937874366\n",
            "Accuracy:  1.0 Loss:  0.05472767793237539\n",
            "Accuracy:  0.9 Loss:  0.29932227920967447\n",
            "Accuracy:  0.95 Loss:  0.09942484076052574\n",
            "Accuracy:  0.8 Loss:  0.3808264460330071\n",
            "Accuracy:  0.8 Loss:  0.6620970773808849\n",
            "Accuracy:  0.8 Loss:  0.33076159574412684\n",
            "Accuracy:  1.0 Loss:  0.05911575655462407\n",
            "Accuracy:  0.9 Loss:  0.3664824474924663\n",
            "Accuracy:  0.95 Loss:  0.18187937761304468\n",
            "Accuracy:  1.0 Loss:  0.04973542271397909\n",
            "Accuracy:  1.0 Loss:  0.1767226785017085\n",
            "Accuracy:  0.9 Loss:  0.4676157632790058\n",
            "Accuracy:  0.9 Loss:  0.32624079305453085\n",
            "epoch: 8\n",
            "Accuracy:  0.9 Loss:  0.23522728024004974\n",
            "Accuracy:  0.85 Loss:  0.42261366349303076\n",
            "Accuracy:  0.85 Loss:  0.21481557102064883\n",
            "Accuracy:  0.9 Loss:  0.3048637911219542\n",
            "Accuracy:  1.0 Loss:  0.0826572974407758\n",
            "Accuracy:  0.85 Loss:  0.22383328118604706\n",
            "Accuracy:  0.85 Loss:  0.6139529165755667\n",
            "Accuracy:  1.0 Loss:  0.05296614733064055\n",
            "Accuracy:  0.9 Loss:  0.29230536772633847\n",
            "Accuracy:  0.95 Loss:  0.10542512345480934\n",
            "Accuracy:  0.75 Loss:  0.3638290657079145\n",
            "Accuracy:  0.8 Loss:  0.6294137916712258\n",
            "Accuracy:  0.8 Loss:  0.3214048516708759\n",
            "Accuracy:  1.0 Loss:  0.05400706040071314\n",
            "Accuracy:  0.9 Loss:  0.3592087405859411\n",
            "Accuracy:  0.95 Loss:  0.18095603642811742\n",
            "Accuracy:  1.0 Loss:  0.04542165762569374\n",
            "Accuracy:  1.0 Loss:  0.16320514730068564\n",
            "Accuracy:  0.9 Loss:  0.46498876500576103\n",
            "Accuracy:  0.9 Loss:  0.3373599309576424\n",
            "epoch: 9\n",
            "Accuracy:  0.9 Loss:  0.23610045915923225\n",
            "Accuracy:  0.85 Loss:  0.4424330375122306\n",
            "Accuracy:  0.85 Loss:  0.18539070159757892\n",
            "Accuracy:  0.9 Loss:  0.2796469919468048\n",
            "Accuracy:  1.0 Loss:  0.0840155837564501\n",
            "Accuracy:  0.85 Loss:  0.21101109207614446\n",
            "Accuracy:  0.85 Loss:  0.5471023180156263\n",
            "Accuracy:  1.0 Loss:  0.05022055210788882\n",
            "Accuracy:  0.9 Loss:  0.30844996725758633\n",
            "Accuracy:  0.95 Loss:  0.10045910231798993\n",
            "Accuracy:  0.75 Loss:  0.36191301369971596\n",
            "Accuracy:  0.8 Loss:  0.6269094644094957\n",
            "Accuracy:  0.85 Loss:  0.3123290314372803\n",
            "Accuracy:  1.0 Loss:  0.05291667190516092\n",
            "Accuracy:  0.85 Loss:  0.3608505729653058\n",
            "Accuracy:  0.95 Loss:  0.17854646960806972\n",
            "Accuracy:  1.0 Loss:  0.0436365957236821\n",
            "Accuracy:  1.0 Loss:  0.15774758017564897\n",
            "Accuracy:  0.9 Loss:  0.4735334331737612\n",
            "Accuracy:  0.9 Loss:  0.3011355438411182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kOmXdAaTpwu",
        "outputId": "75d50d51-327d-44d2-915f-e32c36aba85f"
      },
      "source": [
        "test_probs, test_loss = forward_pass(X_test, y_test, np.eye(n_class)[y_test])\n",
        "test_y_preds = predictions(test_probs)\n",
        "print(accuracy(test_y_preds, y_test))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEzpGTYLPc2v"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}